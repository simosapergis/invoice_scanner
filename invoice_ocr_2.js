#!/usr/bin/env node

import fs from "fs/promises";
import path from "path";
import process from "process";
import OpenAI from "openai";
import vision from "@google-cloud/vision";

const DEFAULT_FILE = "invoice.JPG";
const REQUIRED_FIELDS = [
  "Î—ÎœÎ•Î¡ÎŸÎœÎ—ÎÎ™Î‘",
  "Î‘Î¡Î™Î˜ÎœÎŸÎ£ Î¤Î™ÎœÎŸÎ›ÎŸÎ“Î™ÎŸÎ¥",
  "Î Î¡ÎŸÎœÎ—Î˜Î•Î¥Î¤Î—Î£",
  "Î£Î¥ÎÎŸÎ›ÎŸ Î§Î©Î¡Î™Î£ Î¦Î Î‘",
  "Î¦Î Î‘",
  "Î¤Î•Î›Î™ÎšÎŸ Î ÎŸÎ£ÎŸ"
];
const ACCURACY_FIELD = "Î‘ÎšÎ¡Î™Î’Î•Î™Î‘";
const RESPONSE_FIELDS = [...REQUIRED_FIELDS, ACCURACY_FIELD];

function collectResponseText(response) {
  const chunks = [];

  if (Array.isArray(response?.output)) {
    for (const block of response.output) {
      if (!Array.isArray(block?.content)) continue;
      for (const part of block.content) {
        if (typeof part?.text === "string") {
          chunks.push(part.text);
        } else if (typeof part?.output_text === "string") {
          chunks.push(part.output_text);
        } else if (typeof part?.value === "string") {
          chunks.push(part.value);
        }
      }
    }
  }

  if (Array.isArray(response?.output_text)) {
    chunks.push(...response.output_text);
  }

  return chunks.join("\n").trim();
}

function parseFirstJsonChunk(text) {
  if (!text) {
    throw new Error("The model returned an empty response.");
  }

  try {
    return JSON.parse(text);
  } catch {
    const match = text.match(/\{[\s\S]*\}/);
    if (!match) {
      throw new Error("Could not locate JSON in the model response.");
    }
    return JSON.parse(match[0]);
  }
}

async function main() {
  if (!process.env.OPENAI_API_KEY) {
    throw new Error(
      "Missing OPENAI_API_KEY. Please set the environment variable before running the script."
    );
  }

  const fileArgument = process.argv[2] ?? DEFAULT_FILE;
  const invoicePath = path.resolve(process.cwd(), fileArgument);

  try {
    await fs.access(invoicePath);
  } catch {
    throw new Error(`Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï„Î¹Î¼Î¿Î»Î¿Î³Î¯Î¿Ï…: ${invoicePath}`);
  }

  // 1) OCR Î¼Îµ Google Cloud Vision (documentTextDetection)
  const visionClient = new vision.ImageAnnotatorClient();
  const [result] = await visionClient.documentTextDetection(invoicePath);
  const fullText = result.fullTextAnnotation?.text;

  if (!fullText) {
    throw new Error("Google Cloud Vision did not return any text.");
  }

  // 2) Î”ÎµÏ…Ï„ÎµÏÎ¿Î³ÎµÎ½Î®Ï‚ ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€ÎµÎ´Î¯Ï‰Î½ Î¼Î­ÏƒÏ‰ OpenAI (textâ€‘only)
  const systemPrompt =
    "You are an expert accountant specializing in OCR for European invoices. " +
    "You will receive the raw text extracted from an invoice (which contains Greek text). " +
    "Using ONLY this text, extract the requested fields. " +
    "Respond strictly in JSON that matches the provided schema. " +
    "If a value is missing, return null. Amounts must use dot-decimal notation (e.g. 1234.56) and omit currency symbols.";

  const extractionPrompt =
    "Î Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÏƒÎ¿Ï… Î´Î¯Î½Ï‰ ÎŸÎ›ÎŸ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎ½ÏŒÏ‚ Ï„Î¹Î¼Î¿Î»Î¿Î³Î¯Î¿Ï… ÏŒÏ€Ï‰Ï‚ Ï€ÏÎ¿Î­ÎºÏ…ÏˆÎµ Î±Ï€ÏŒ OCR. " +
    "Î Î±ÏÎ±ÎºÎ±Î»ÏŽ ÎµÎ½Ï„ÏŒÏ€Î¹ÏƒÎµ ÎºÎ±Î¹ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€ÎµÎ´Î¯Î± ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬. " +
    "Î•Ï€Î¹Ï€Î»Î­Î¿Î½, Ï€ÏÏŒÏƒÎ¸ÎµÏƒÎµ ÎºÎ±Î¹ Î­Î½Î± Ï€ÎµÎ´Î¯Î¿ Â«Î‘ÎšÎ¡Î™Î’Î•Î™Î‘Â» Î¼Îµ Ï€Î¿ÏƒÎ¿ÏƒÏ„Î¹Î±Î¯Î± ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· (0-100%) " +
    "Î³Î¹Î± Ï„Î¿ Ï€ÏŒÏƒÎ¿ Î²Î­Î²Î±Î¹Î¿Ï‚ ÎµÎ¯ÏƒÎ±Î¹ ÏŒÏ„Î¹ ÏŒÎ»Î± Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ‰ÏƒÏ„Î¬:\n" +
    RESPONSE_FIELDS.map((field, index) => `${index + 1}. ${field}`).join("\n") +
    "\n\nÎ‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï„Î¿Ï… Ï„Î¹Î¼Î¿Î»Î¿Î³Î¯Î¿Ï…:\n\n" +
    fullText;

  const client = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });

  const response = await client.responses.create({
    model: "gpt-4o-mini",
    input: [
      {
        role: "system",
        content: [
          {
            type: "input_text",
            text: systemPrompt
          }
        ]
      },
      {
        role: "user",
        content: [
          {
            type: "input_text",
            text: extractionPrompt
          }
        ]
      }
    ],
    max_output_tokens: 800
  });

  const rawText = collectResponseText(response);
  const extracted = parseFirstJsonChunk(rawText);

  console.log("ðŸ“„  OCR (Vision + GPT) Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±:");
  for (const field of REQUIRED_FIELDS) {
    const value = extracted[field];
    console.log(`- ${field}: ${value ?? "â€”"}`);
  }

  if (ACCURACY_FIELD in extracted) {
    const accuracyValue = extracted[ACCURACY_FIELD];
    console.log(`- ${ACCURACY_FIELD}: ${accuracyValue ?? "â€”"}`);
  }
}

main().catch((error) => {
  console.error("Failed to run invoice_ocr_2:", error.message);
  process.exitCode = 1;
});


